{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transportation_tutorials as tt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "A popular package for developing linear regression models in Python\n",
    "is `statsmodels`.  This packages includes an extensive set of tools\n",
    "for statisitical modeling, but in this tutorial we will focus on \n",
    "linear regression models.\n",
    "\n",
    "Generally, linear regression models will be developed using a \n",
    "`pandas.DataFrame` containing both independent (explanatory) and \n",
    "dependent (target) variables.  We'll work with data in the \n",
    "households and trips table from the Jupiter study area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = pd.read_csv(tt.data('SERPM8-BASE2015-HOUSEHOLDS'), index_col=0)\n",
    "hh.set_index('hh_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips = pd.read_csv(tt.data('SERPM8-BASE2015-TRIPS'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to develop a linear regression model to predict trip generation\n",
    "by households, we'll need to merge these two data tables, tabulating the number\n",
    "of trips taken by each household. (See the tutorial on \n",
    "[grouping](./basic-analysis-with-pandas.html#Grouping) for more details on how\n",
    "to do this)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = hh.merge(\n",
    "    trips.groupby(['hh_id']).size().rename('n_trips'), \n",
    "    left_on=['hh_id'], \n",
    "    right_index=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can review what variables we now have in the `hh` DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17260 entries, 1690841 to 1726370\n",
      "Data columns (total 9 columns):\n",
      "home_mgra       17260 non-null int64\n",
      "income          17260 non-null int64\n",
      "autos           17260 non-null int64\n",
      "transponder     17260 non-null int64\n",
      "cdap_pattern    17260 non-null object\n",
      "jtf_choice      17260 non-null int64\n",
      "autotech        17260 non-null int64\n",
      "tncmemb         17260 non-null int64\n",
      "n_trips         17260 non-null int64\n",
      "dtypes: int64(8), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    }
   ],
   "source": [
    "hh.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we suppose that the number of trips made by a household is \n",
    "a function of income and the number of automobiles owned, we can\n",
    "create an ordinary least squares regression model, and find the \n",
    "best fitting parameters like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                n_trips   R-squared:                       0.229\n",
      "Model:                            OLS   Adj. R-squared:                  0.229\n",
      "Method:                 Least Squares   F-statistic:                     2563.\n",
      "Date:                Thu, 08 Aug 2019   Prob (F-statistic):               0.00\n",
      "Time:                        13:45:17   Log-Likelihood:                -48167.\n",
      "No. Observations:               17260   AIC:                         9.634e+04\n",
      "Df Residuals:                   17257   BIC:                         9.636e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          2.4460      0.073     33.694      0.000       2.304       2.588\n",
      "autos          2.5804      0.039     65.547      0.000       2.503       2.658\n",
      "income       1.97e-06   2.79e-07      7.049      0.000    1.42e-06    2.52e-06\n",
      "==============================================================================\n",
      "Omnibus:                     4116.620   Durbin-Watson:                   1.926\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            11185.853\n",
      "Skew:                           1.273   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.011   Cond. No.                     4.14e+05\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 4.14e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jpn/anaconda/envs/tt/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "mod = sm.OLS(\n",
    "    hh.n_trips, \n",
    "    sm.add_constant(hh[['autos','income']])\n",
    ")\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `hh` dataframes contains a variety of other columns of data, but\n",
    "since we're not interested in using them for this model, they can be implicitly \n",
    "omitted by creating a dataframe view that includes only the variables we do want.\n",
    "\n",
    "Also, we use `sm.add_constant`, which includes a constant in the regression\n",
    "function.  By default, the `statsmodels` module does *not* include a constant\n",
    "in an ordinary least squares (OLS) model, so you must explicitly add one \n",
    "to the explanatory variables to include it.\n",
    "\n",
    "The output of the model `summary()` is relatively extensive and includes a \n",
    "large number of statistical measures and tests that may or may not interest\n",
    "you.  The most important of these measures include the coefficient estimates\n",
    "shown in the center panel of this report, as well as the R-squared measure at\n",
    "the upper right.\n",
    "\n",
    "One other item that may be concerning in this report is the second warning at\n",
    "the bottom, which reports that there may be some numerical problem with the model.\n",
    "This problem is actually reflected also in the coefficients themselves, as the \n",
    "coefficient for income is many orders of magnitide different from the others.  \n",
    "This is reasonable and intuititve: the impact of a unit (single dollar) change in annual\n",
    "household income is insignificant compared to a unit (single car) change in\n",
    "automobile ownership.  If we review the standard deviations of these explanatory\n",
    "variables, we can also see they vary greatly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "const          0.000000\n",
       "autos          0.801841\n",
       "income    112974.383573\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm.add_constant(hh[['autos','income']]).std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A magnitude variance this large is not problematic in raw statistical theory,\n",
    "but it can introduce numerical stability problems when using computers to \n",
    "represent these models.  To solve this issue, we can simply scale one or more \n",
    "variables to more consistent variance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh['income_100k'] = hh.income / 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                n_trips   R-squared:                       0.229\n",
      "Model:                            OLS   Adj. R-squared:                  0.229\n",
      "Method:                 Least Squares   F-statistic:                     2563.\n",
      "Date:                Thu, 08 Aug 2019   Prob (F-statistic):               0.00\n",
      "Time:                        13:45:17   Log-Likelihood:                -48167.\n",
      "No. Observations:               17260   AIC:                         9.634e+04\n",
      "Df Residuals:                   17257   BIC:                         9.636e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           2.4460      0.073     33.694      0.000       2.304       2.588\n",
      "autos           2.5804      0.039     65.547      0.000       2.503       2.658\n",
      "income_100k     0.1970      0.028      7.049      0.000       0.142       0.252\n",
      "==============================================================================\n",
      "Omnibus:                     4116.620   Durbin-Watson:                   1.926\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            11185.853\n",
      "Skew:                           1.273   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.011   Cond. No.                         6.60\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod = sm.OLS(\n",
    "    hh.n_trips, \n",
    "    sm.add_constant(hh[['autos','income_100k']])\n",
    ")\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared and t-statistics of this model are the same as before,\n",
    "as this is in effect the same model as above.  But in this revised model, the\n",
    "magnitude of the income coefficient is now much closer to that of the other\n",
    "coefficients, and the \"condition number\" warning is not present in the summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Piecewise Linear Functions\n",
    "\n",
    "OLS linear regression models are by design written as linear-in-parameters\n",
    "models, but that does not mean that the explanitory data cannot be first\n",
    "transformed, for example by using a piece-wise linear expansion.  The `larch`\n",
    "package includes a `piecewise_expansion` function that can expand a single\n",
    "column of data in a pandas.DataFrame into multiple columns based on defined\n",
    "breakpoints.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from larch.util.data_expansion import piecewise_expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, to create a piecewise linear version of household income,\n",
    "with break points at \\$25 and \\$75 thouand, we could write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>piece(income,None,25000)</th>\n",
       "      <th>piece(income,25000,75000)</th>\n",
       "      <th>piece(income,75000,None)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hh_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1690841</th>\n",
       "      <td>25000</td>\n",
       "      <td>50000</td>\n",
       "      <td>437000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690961</th>\n",
       "      <td>25000</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690866</th>\n",
       "      <td>25000</td>\n",
       "      <td>50000</td>\n",
       "      <td>75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690895</th>\n",
       "      <td>25000</td>\n",
       "      <td>50000</td>\n",
       "      <td>29000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690933</th>\n",
       "      <td>25000</td>\n",
       "      <td>50000</td>\n",
       "      <td>20000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         piece(income,None,25000)  piece(income,25000,75000)  \\\n",
       "hh_id                                                          \n",
       "1690841                     25000                      50000   \n",
       "1690961                     25000                       2500   \n",
       "1690866                     25000                      50000   \n",
       "1690895                     25000                      50000   \n",
       "1690933                     25000                      50000   \n",
       "\n",
       "         piece(income,75000,None)  \n",
       "hh_id                              \n",
       "1690841                    437000  \n",
       "1690961                         0  \n",
       "1690866                     75000  \n",
       "1690895                     29000  \n",
       "1690933                     20000  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "piecewise_expansion(hh.income, [25_000, 75_000]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is three columns of data instead of one, with the first giving \n",
    "income up to the lower breakpoint, the next giving income between the \n",
    "two breakpoints, and the last giving the amount of income above the\n",
    "top breakpoint.\n",
    "\n",
    "We can readily concatenate this expanded data with any other explanatory \n",
    "variables by using `pandas.concat`.  Note that by default this function\n",
    "concatenates dataframes vertically (combining columns and stacking rows), \n",
    "but in this case we want to concatenate horizontally (combining rows and\n",
    "stacking columns).  We can achieve this by also passing `axis=1` to the\n",
    "function in addition to the list of dataframes to concatenate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autos</th>\n",
       "      <th>piece(income_100k,None,0.25)</th>\n",
       "      <th>piece(income_100k,0.25,0.75)</th>\n",
       "      <th>piece(income_100k,0.75,None)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hh_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1690841</th>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500</td>\n",
       "      <td>4.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690961</th>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690866</th>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690895</th>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690933</th>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         autos  piece(income_100k,None,0.25)  piece(income_100k,0.25,0.75)  \\\n",
       "hh_id                                                                        \n",
       "1690841      2                          0.25                         0.500   \n",
       "1690961      1                          0.25                         0.025   \n",
       "1690866      2                          0.25                         0.500   \n",
       "1690895      2                          0.25                         0.500   \n",
       "1690933      2                          0.25                         0.500   \n",
       "\n",
       "         piece(income_100k,0.75,None)  \n",
       "hh_id                                  \n",
       "1690841                          4.37  \n",
       "1690961                          0.00  \n",
       "1690866                          0.75  \n",
       "1690895                          0.29  \n",
       "1690933                          0.20  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh_edited = pd.concat([\n",
    "    hh.autos,\n",
    "    piecewise_expansion(hh.income_100k, [.25, .75]),\n",
    "], axis=1)\n",
    "\n",
    "hh_edited.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use this modified dataframe to construct a piecewise linear OLS regression model.\n",
    "Because the original and modified dataframes have the same index (i.e. number and order of rows)\n",
    "we can mix them in the OLS defintion, using the `n_trips` column from the original as the dependent \n",
    "variable and the explanatory data from the modified dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                n_trips   R-squared:                       0.231\n",
      "Model:                            OLS   Adj. R-squared:                  0.231\n",
      "Method:                 Least Squares   F-statistic:                     1297.\n",
      "Date:                Thu, 08 Aug 2019   Prob (F-statistic):               0.00\n",
      "Time:                        13:45:17   Log-Likelihood:                -48143.\n",
      "No. Observations:               17260   AIC:                         9.630e+04\n",
      "Df Residuals:                   17255   BIC:                         9.633e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "================================================================================================\n",
      "                                   coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------------\n",
      "const                            1.9177      0.153     12.542      0.000       1.618       2.217\n",
      "autos                            2.4769      0.042     58.560      0.000       2.394       2.560\n",
      "piece(income_100k,None,0.25)     2.2983      0.722      3.181      0.001       0.882       3.714\n",
      "piece(income_100k,0.25,0.75)     1.0124      0.204      4.972      0.000       0.613       1.412\n",
      "piece(income_100k,0.75,None)     0.0977      0.033      3.002      0.003       0.034       0.162\n",
      "==============================================================================\n",
      "Omnibus:                     4132.769   Durbin-Watson:                   1.925\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            11235.615\n",
      "Skew:                           1.278   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.015   Cond. No.                         56.0\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jpn/anaconda/envs/tt/lib/python3.7/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "mod = sm.OLS(\n",
    "    hh.n_trips, \n",
    "    sm.add_constant(hh_edited)\n",
    ")\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Functions\n",
    "\n",
    "In addition to piecewise linear terms in the regression equation, \n",
    "standard OLS allows for any arbitrary non-linear transformation.\n",
    "Students of statistics will be familiar with fitting a polynomial\n",
    "function with OLS coefficients, and this can be done using `statsmodels`\n",
    "for example by explicitly computing the desired polynomial terms\n",
    "before estimating model parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh['autos^2'] = hh['autos'] ** 2\n",
    "hh['income^2'] = hh['income_100k'] ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                n_trips   R-squared:                       0.230\n",
      "Model:                            OLS   Adj. R-squared:                  0.229\n",
      "Method:                 Least Squares   F-statistic:                     1286.\n",
      "Date:                Thu, 08 Aug 2019   Prob (F-statistic):               0.00\n",
      "Time:                        13:45:17   Log-Likelihood:                -48160.\n",
      "No. Observations:               17260   AIC:                         9.633e+04\n",
      "Df Residuals:                   17255   BIC:                         9.637e+04\n",
      "Df Model:                           4                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "===============================================================================\n",
      "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-------------------------------------------------------------------------------\n",
      "const           2.6596      0.127     20.926      0.000       2.411       2.909\n",
      "autos           2.2161      0.139     15.970      0.000       1.944       2.488\n",
      "income_100k     0.3748      0.067      5.578      0.000       0.243       0.507\n",
      "autos^2         0.0839      0.033      2.545      0.011       0.019       0.148\n",
      "income^2       -0.0314      0.011     -2.788      0.005      -0.054      -0.009\n",
      "==============================================================================\n",
      "Omnibus:                     4098.383   Durbin-Watson:                   1.925\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            11134.434\n",
      "Skew:                           1.268   Prob(JB):                         0.00\n",
      "Kurtosis:                       6.009   Cond. No.                         46.6\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod = sm.OLS(\n",
    "    hh.n_trips, \n",
    "    sm.add_constant(hh[['autos','income_100k', 'autos^2', 'income^2']])\n",
    ")\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, polynomial terms can be created automatically for every \n",
    "column in the source data, as well as for interactions, using \n",
    "the `PolynomialFeatures` preprocessor from the `sklearn` package.\n",
    "This tool doesn't automatically maintain the DataFrame formatting\n",
    "when applied (instead it outputs a simple array of values), \n",
    "but it is simple to write a small function that will do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial(x, **kwargs):\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    poly = PolynomialFeatures(**kwargs)\n",
    "    arr = poly.fit_transform(x)\n",
    "    return pd.DataFrame(arr, columns=poly.get_feature_names(x.columns), index=x.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can use the function to calculate polynomial terms automatically. \n",
    "In this example, by setting the `degree` to 3, we not only get squared and \n",
    "cubed versions of the two parameters, but also all the interactions of these\n",
    "parameters up to degree 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>autos</th>\n",
       "      <th>income_100k</th>\n",
       "      <th>autos^2</th>\n",
       "      <th>autos income_100k</th>\n",
       "      <th>income_100k^2</th>\n",
       "      <th>autos^3</th>\n",
       "      <th>autos^2 income_100k</th>\n",
       "      <th>autos income_100k^2</th>\n",
       "      <th>income_100k^3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hh_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1690841</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.120</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.240</td>\n",
       "      <td>26.214400</td>\n",
       "      <td>8.0</td>\n",
       "      <td>20.480</td>\n",
       "      <td>52.428800</td>\n",
       "      <td>134.217728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690961</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.275</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.075625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.275</td>\n",
       "      <td>0.075625</td>\n",
       "      <td>0.020797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690866</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.500</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690895</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.040</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.080</td>\n",
       "      <td>1.081600</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.160</td>\n",
       "      <td>2.163200</td>\n",
       "      <td>1.124864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690933</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.950</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.900</td>\n",
       "      <td>0.902500</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.800</td>\n",
       "      <td>1.805000</td>\n",
       "      <td>0.857375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1  autos  income_100k  autos^2  autos income_100k  income_100k^2  \\\n",
       "hh_id                                                                         \n",
       "1690841  1.0    2.0        5.120      4.0             10.240      26.214400   \n",
       "1690961  1.0    1.0        0.275      1.0              0.275       0.075625   \n",
       "1690866  1.0    2.0        1.500      4.0              3.000       2.250000   \n",
       "1690895  1.0    2.0        1.040      4.0              2.080       1.081600   \n",
       "1690933  1.0    2.0        0.950      4.0              1.900       0.902500   \n",
       "\n",
       "         autos^3  autos^2 income_100k  autos income_100k^2  income_100k^3  \n",
       "hh_id                                                                      \n",
       "1690841      8.0               20.480            52.428800     134.217728  \n",
       "1690961      1.0                0.275             0.075625       0.020797  \n",
       "1690866      8.0                6.000             4.500000       3.375000  \n",
       "1690895      8.0                4.160             2.163200       1.124864  \n",
       "1690933      8.0                3.800             1.805000       0.857375  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh_poly = polynomial(hh[['autos','income_100k']], degree=3)\n",
    "hh_poly.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great care should be used with this automatic polynomial expansion of the data, \n",
    "as it is easy to end up with an overfitted model, especially when using a tool\n",
    "like OLS that does not attempt to self-correct to limit overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                n_trips   R-squared:                       0.236\n",
      "Model:                            OLS   Adj. R-squared:                  0.235\n",
      "Method:                 Least Squares   F-statistic:                     590.5\n",
      "Date:                Thu, 08 Aug 2019   Prob (F-statistic):               0.00\n",
      "Time:                        13:45:17   Log-Likelihood:                -48093.\n",
      "No. Observations:               17260   AIC:                         9.621e+04\n",
      "Df Residuals:                   17250   BIC:                         9.628e+04\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "1                       3.6606      0.192     19.086      0.000       3.285       4.037\n",
      "autos                  -0.1241      0.321     -0.386      0.699      -0.754       0.506\n",
      "income_100k             0.6579      0.223      2.955      0.003       0.222       1.094\n",
      "autos^2                 1.2151      0.178      6.828      0.000       0.866       1.564\n",
      "autos income_100k       0.5617      0.182      3.088      0.002       0.205       0.918\n",
      "income_100k^2          -0.3633      0.052     -6.984      0.000      -0.465      -0.261\n",
      "autos^3                -0.1641      0.030     -5.515      0.000      -0.222      -0.106\n",
      "autos^2 income_100k    -0.1079      0.039     -2.790      0.005      -0.184      -0.032\n",
      "autos income_100k^2    -0.0216      0.016     -1.337      0.181      -0.053       0.010\n",
      "income_100k^3           0.0349      0.004      8.257      0.000       0.027       0.043\n",
      "==============================================================================\n",
      "Omnibus:                     4055.002   Durbin-Watson:                   1.926\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10960.315\n",
      "Skew:                           1.257   Prob(JB):                         0.00\n",
      "Kurtosis:                       5.987   Cond. No.                         659.\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "mod = sm.OLS(\n",
    "    hh.n_trips, \n",
    "    hh_poly\n",
    ")\n",
    "res = mod.fit()\n",
    "print(res.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
